{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import itertools\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "\n",
    "from fastai.basic_data import DataBunch\n",
    "from fastai.basic_train import Learner\n",
    "from fastai.train import lr_find, fit_one_cycle\n",
    "from fastprogress import progress_bar\n",
    "\n",
    "from utils import download_wikitext, prepare_data, load_glove\n",
    "from nn_toolkit.vocab import Vocab, VocabEncoder\n",
    "\n",
    "jtplot.style()\n",
    "%load_ext autoreload\n",
    "%matplotlib notebook\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cooccurence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cooccurence:\n",
    "    def __init__(self, vocab: Vocab, window: int, distance_mode: str, num_workers: int) -> None:\n",
    "        self.vocab = vocab\n",
    "        self.window = window\n",
    "        self.distance_mode = distance_mode\n",
    "        self.counts = defaultdict(lambda: defaultdict(float))\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def dict_to_df(self):\n",
    "        data = []\n",
    "        for token1, token_counts in self.counts.items():\n",
    "            for token2, count in token_counts.items():\n",
    "                data.append({'token1': token1, 'token2': token2, 'count': count})\n",
    "        del self.counts\n",
    "        df = pd.DataFrame(data)\n",
    "        index = pd.MultiIndex.from_frame(df[['token1', 'token2']])\n",
    "        return pd.DataFrame(df['count'].values, index=index, columns=['count'])\n",
    "\n",
    "    def update(self, documents: List[List[str]]) -> None:\n",
    "        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "            futures = [executor.submit(self.add_doc, doc) for doc in documents]\n",
    "            pbar = progress_bar(concurrent.futures.as_completed(futures), total=len(documents))\n",
    "            for f in pbar:\n",
    "                f.result()\n",
    "\n",
    "    def add_doc(self, doc: List[str]) -> None:\n",
    "        idx = 0\n",
    "        while idx < len(doc):\n",
    "            left = self.get_left_context(doc, idx)\n",
    "            right = self.get_right_context(doc, idx)\n",
    "            self.add_context(left, doc[idx], 'left')\n",
    "            self.add_context(right, doc[idx], 'right')\n",
    "            idx += 1\n",
    "            assert len(self.counts) <= self.vocab.size\n",
    "\n",
    "    def add_context(self, context: List[str], target: str, mode: str) -> None:\n",
    "        if target not in self.vocab: target = '<unk>'\n",
    "        for i, token in enumerate(context):\n",
    "            if token not in self.vocab: token = '<unk>'\n",
    "            d = (i + 1) if mode == 'right' else (self.window - i)\n",
    "            self.counts[target][token] += self.distance_weight(d)\n",
    "        return\n",
    "\n",
    "    def get_right_context(self, doc: List[str], idx: int) -> List[str]:\n",
    "        right_edge = min(len(doc), idx+self.window+1)\n",
    "        right = doc[idx+1: right_edge]\n",
    "        return right\n",
    "\n",
    "    def get_left_context(self, doc: List[str], idx: int) -> List[str]:\n",
    "        left_edge = max(0, idx-self.window)\n",
    "        left = doc[left_edge: idx]\n",
    "        return left\n",
    "\n",
    "    def distance_weight(self, d: int):\n",
    "        if self.distance_mode == 'inverse':\n",
    "            return 1. / d\n",
    "        return 1.\n",
    "\n",
    "    def _get_from_str(self, key: str):\n",
    "        return self.counts[key]\n",
    "\n",
    "    def _get_from_int(self, key: int):\n",
    "        key = self.vocab.int_to_token[key]\n",
    "        return self._get_from_str(key)\n",
    "\n",
    "    def __getitem__(self, key: Union[str, int]):\n",
    "        if isinstance(key, int):\n",
    "            return self._get_from_int(key)\n",
    "        elif isinstance(key, str):\n",
    "            return self._get_from_str(key)\n",
    "        else:\n",
    "            t = type(key)\n",
    "            raise TypeError(f\"Can not look up using type {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CooDataset(utils.data.Dataset):\n",
    "    def __init__(self, coo: Cooccurence) -> None:\n",
    "        self.coo = coo\n",
    "        self.Xij = coo.dict_to_df()\n",
    "        self.vocab = coo.vocab\n",
    "        \n",
    "        self._prep_df()\n",
    "        \n",
    "    def _prep_df(self):\n",
    "        token1 = pd.Series(self.Xij.index.get_level_values('token1'))\n",
    "        token2 = pd.Series(self.Xij.index.get_level_values('token2'))\n",
    "        self.i = [self.vocab[t] for t in token1]\n",
    "        self.j = [self.vocab[t] for t in token2]\n",
    "        self.counts = self.Xij['count'].tolist()\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.i[idx], self.j[idx], self.counts[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Xij.shape[0]\n",
    "\n",
    "def collate_batch(batch) -> Tuple[torch.Tensor]:\n",
    "    N = len(batch)\n",
    "    i = torch.empty(N, dtype=torch.int64)\n",
    "    j = torch.empty(N, dtype=torch.int64)\n",
    "    Xij = torch.empty(N, dtype=torch.float32)\n",
    "    for k, sample in enumerate(batch):\n",
    "        i[k], j[k], Xij[k] = sample\n",
    "    return (i, j), Xij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Glove(nn.Module):\n",
    "    def __init__(self, vocab: Vocab, embedding_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.embedding_dim = embedding_dim\n",
    "        lim = embedding_dim\n",
    "        self.W = nn.Parameter(self._W_init())\n",
    "        self.Wt = nn.Parameter(self._W_init())\n",
    "        self.b = nn.Parameter(self._b_init())\n",
    "        self.bt = nn.Parameter(self._b_init())\n",
    "\n",
    "    def forward(self, i: torch.LongTensor, j: torch.LongTensor) -> torch.Tensor:\n",
    "        wi = F.embedding(i, self.W, padding_idx=self.vocab.pad_index)  # (N, e)\n",
    "        bi = F.embedding(i, self.b, padding_idx=self.vocab.pad_index).squeeze()  # (N,)\n",
    "        wj = F.embedding(j, self.Wt, padding_idx=self.vocab.pad_index)  # (N, e)\n",
    "        bj = F.embedding(j, self.bt, padding_idx=self.vocab.pad_index).squeeze()  # (N,)\n",
    "\n",
    "        dot = (wi * wj).sum(1)  # (N,)\n",
    "        p = dot + bi + bj\n",
    "        return p\n",
    "\n",
    "    def _W_init(self) -> torch.Tensor:\n",
    "        size = [self.vocab.size, self.embedding_dim]\n",
    "        W = torch.empty(*size).uniform_() - 0.5\n",
    "        W = W / math.sqrt(self.embedding_dim)\n",
    "        return W\n",
    "\n",
    "    def _b_init(self) -> torch.Tensor:\n",
    "        size = [self.vocab.size, 1]\n",
    "        b = torch.empty(*size).uniform_() - 0.5\n",
    "        b = b / math.sqrt(self.embedding_dim)\n",
    "        return b\n",
    "\n",
    "    def __getitem__(self, token: str):\n",
    "        idx = self.vocab[token]\n",
    "        return self.W[idx]\n",
    "\n",
    "    def similarity(self, token1: str, token2: str) -> float:\n",
    "        with torch.no_grad():\n",
    "            vec1 = self[token1]\n",
    "            vec2 = self[token2]\n",
    "            norm = torch.norm(vec1) * torch.norm(vec2)\n",
    "            dot = (vec1 * vec2).sum() / norm\n",
    "        return dot.item()\n",
    "    \n",
    "    def analogy(self, token1: str, token2: str, token3: str, k: int = 5) -> str:\n",
    "        \"\"\"Token1 - Token2 + Token3\"\"\"\n",
    "        with torch.no_grad():\n",
    "            vec1 = self[token1]\n",
    "            vec2 = self[token2]\n",
    "            vec3 = self[token3]\n",
    "            diff = vec1 - vec2 + vec3\n",
    "            diff_norm = torch.norm(diff)\n",
    "            w_norm = torch.norm(self.W, dim=1, keepdim=True)\n",
    "            similarity  = self.W @ diff_norm / (w_norm * diff_norm)\n",
    "            topk = torch.topk(similarity, k)\n",
    "            idx = topk.indices.tolist()[0:k]\n",
    "            vals = topk.values.tolist()[0:k]\n",
    "        words = [self.vocab.get(i, reverse=True) for i in idx]\n",
    "        return list(zip(words, vals))\n",
    "\n",
    "    def most_similar(self, token: str, k: int = 10) -> List[Tuple[str, float]]:\n",
    "        with torch.no_grad():\n",
    "            vec = self[token].unsqueeze(0)  # (1, e)\n",
    "            dot = (vec @ self.W.t()).squeeze()  # (N, )\n",
    "            norm = torch.norm(vec, dim=1) * torch.norm(self.W, dim=1)\n",
    "            norm = torch.clamp(norm, 1e-9, float('inf'))\n",
    "            similarity = dot / norm\n",
    "            topk = torch.topk(similarity, k)\n",
    "        idxs = topk.indices.tolist()[0:k]\n",
    "        vals = topk.values.tolist()[0:k]\n",
    "        words = [self.vocab.get(i, reverse=True) for i in idxs]\n",
    "        return list(zip(words, vals))\n",
    "    \n",
    "    def to_text(self) -> str:\n",
    "        \"\"\"Represent model as glove txt format.\"\"\"\n",
    "        lines = []\n",
    "        for token in self.vocab:\n",
    "            vector = self[token].tolist()\n",
    "            vec_str = ' '.join(map(str, vector))\n",
    "            line = f'{token} {vec_str}'\n",
    "            lines.append(line)\n",
    "        return '\\n'.join(lines)\n",
    "    \n",
    "    def save_as_text(self, path: Union[Path, str]) -> None:\n",
    "        with open(path, 'w') as fw:\n",
    "            fw.write(self.to_text())\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GloveLoss(nn.modules.loss._Loss):\n",
    "    \"\"\"\n",
    "    Weighted MSE summed, not averaged, over the vocabulary.\n",
    "    \n",
    "    Defaults are set to values in the paper.\n",
    "    https://github.com/stanfordnlp/GloVe/blob/master/src/glove.c#L55\n",
    "    https://nlp.stanford.edu/pubs/glove.pdf\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xmax : int\n",
    "        threshold to apply maximum weighting in the loss function, by default 100\n",
    "    alpha : float\n",
    "        power in weighting function, by default 0.75\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, xmax: int = 100, alpha: float = 0.75) -> None:\n",
    "        super().__init__()\n",
    "        self.xmax = xmax\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, y_hat, Xij) -> torch.Tensor:\n",
    "        w = self.f(Xij)\n",
    "        mse = self.mse(y_hat, Xij)\n",
    "        assert mse.size(0) == y_hat.size(0)\n",
    "        return (w * mse).sum()\n",
    "        \n",
    "    def f(self, Xij:torch.LongTensor) -> torch.FloatTensor:\n",
    "        w = Xij / self.xmax\n",
    "        return torch.clamp(w, 0., 1.).pow(self.alpha)\n",
    "    \n",
    "    def mse(self, y_hat: torch.FloatTensor, Xij: torch.LongTensor) -> torch.FloatTensor:\n",
    "        Xij = Xij.to(torch.float32)\n",
    "        return F.mse_loss(y_hat, torch.log(Xij + 1.), reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa3c949d0d64d20ab7f27d1543d0ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78107), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe8f4b7b0f140d88d42e9037563db51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8196), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "text_file = Path('data/raw/wikitext-2-v1.zip')\n",
    "download_wikitext(text_file)\n",
    "\n",
    "train_sents = prepare_data(text_file, mode='train', sampling_rate=1., seed=seed)\n",
    "val_sents = prepare_data(text_file, mode='valid', sampling_rate=1., seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 28914\n"
     ]
    }
   ],
   "source": [
    "train_tokens = Counter([t for sent in train_sents for t in sent])\n",
    "max_vocab = 60000\n",
    "vocab = Vocab([t for t, _ in train_tokens.most_common(max_vocab)])\n",
    "print('Vocab size:', vocab.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cooccurence Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='78107' class='' max='78107', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [78107/78107 00:38<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8196' class='' max='8196', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8196/8196 00:03<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window = 15\n",
    "num_workers = 6\n",
    "d_mode = 'inverse'\n",
    "\n",
    "train_coo = Cooccurence(vocab=vocab, window=window, distance_mode=d_mode, num_workers=num_workers)\n",
    "val_coo = Cooccurence(vocab=vocab, window=window, distance_mode=d_mode, num_workers=num_workers)\n",
    "train_coo.update(train_sents)\n",
    "val_coo.update(val_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CooDataset(train_coo)\n",
    "val_ds = CooDataset(val_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If distance mode is not inverse, the following values are the number of words.\n",
      "Total weight in train: 9359889.410661587\n",
      "Total weight in val: 973996.0327478057\n"
     ]
    }
   ],
   "source": [
    "bs = 128\n",
    "pm = False\n",
    "\n",
    "train_dl = utils.data.DataLoader(\n",
    "    train_ds, batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=pm\n",
    ")\n",
    "val_dl = utils.data.DataLoader(\n",
    "    val_ds, batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=pm\n",
    ")\n",
    "\n",
    "data = DataBunch(\n",
    "    train_dl=train_dl, valid_dl=val_dl,\n",
    "    collate_fn=collate_batch,\n",
    "    device='cuda:0'\n",
    ")\n",
    "\n",
    "print('If distance mode is not inverse, the following values are the number of words.')\n",
    "print('Total weight in train:', train_ds.Xij['count'].sum())\n",
    "print('Total weight in val:', val_ds.Xij['count'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Glove(vocab, 300)\n",
    "model.to(data.device)\n",
    "learner = Learner(\n",
    "    data,\n",
    "    model,\n",
    "    loss_func=GloveLoss(xmax=100, alpha=0.75),\n",
    "    opt_func=optim.AdamW\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.660849</td>\n",
       "      <td>4.832432</td>\n",
       "      <td>06:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      16.00% [4/25 24:57<2:11:03]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.297681</td>\n",
       "      <td>4.003604</td>\n",
       "      <td>06:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.477157</td>\n",
       "      <td>3.811065</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.780805</td>\n",
       "      <td>3.686398</td>\n",
       "      <td>06:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.172549</td>\n",
       "      <td>3.560981</td>\n",
       "      <td>06:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6296' class='' max='66925', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      9.41% [6296/66925 00:34<05:36 1.8461]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# glove code hyperparams\n",
    "# lr = 0.05\n",
    "# num_epochs = 25\n",
    "# glove code uses lr of 0.05 \n",
    "# https://github.com/stanfordnlp/GloVe/blob/master/src/glove.c\n",
    "maxlr = 0.05\n",
    "minlr = 5e-5\n",
    "cycles = 2\n",
    "epochs = 25\n",
    "\n",
    "learner.fit_one_cycle(cycles, max_lr=maxlr)\n",
    "learner.recorder.plot_lr()\n",
    "learner.fit(epochs, lr=minlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010557662695646286\n",
      "0.04428711533546448\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('boy', 'ball'))\n",
    "print(model.similarity('girl', 'ball'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.9999998807907104),\n",
       " ('henry', 0.45483022928237915),\n",
       " ('william', 0.39781129360198975),\n",
       " ('charles', 0.3856470584869385),\n",
       " ('john', 0.37961480021476746)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('king', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 1.0),\n",
       " ('holy', 0.3933846652507782),\n",
       " ('dominican', 0.3632296025753021),\n",
       " ('lack', 0.35511961579322815),\n",
       " ('ultimately', 0.35221707820892334)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('queen', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('girl', 0.9999998807907104),\n",
       " ('ellington', 0.3397264778614044),\n",
       " ('pdr', 0.30239516496658325),\n",
       " ('boy', 0.29481378197669983),\n",
       " ('woman', 0.28253433108329773)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('girl', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boy', 1.0),\n",
       " ('child', 0.3289439380168915),\n",
       " ('cold', 0.3127919137477875),\n",
       " ('lizard', 0.29986217617988586),\n",
       " ('girl', 0.29481378197669983)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('boy', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.0034117086324840784),\n",
       " ('man', 0.002597410697489977),\n",
       " ('filmography', 0.0017281401669606566),\n",
       " ('john', 0.0015856641111895442),\n",
       " ('lottery', 0.0015129103558138013)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.analogy('man', 'woman', 'king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate.evaluate import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'torch_glove.{model.embedding_dim}d.txt'\n",
    "model.save_as_text(f'models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayen/Learn/wordvec/evaluate/evaluate.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  W_norm = (W.T / d).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-common-countries.txt:\n",
      "ACCURACY TOP1: 0.00% (0/420)\n",
      "capital-world.txt:\n",
      "ACCURACY TOP1: 0.00% (0/758)\n",
      "currency.txt:\n",
      "ACCURACY TOP1: 0.00% (0/70)\n",
      "city-in-state.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1114)\n",
      "family.txt:\n",
      "ACCURACY TOP1: 0.00% (0/342)\n",
      "gram1-adjective-to-adverb.txt:\n",
      "ACCURACY TOP1: 0.00% (0/702)\n",
      "gram2-opposite.txt:\n",
      "ACCURACY TOP1: 0.00% (0/272)\n",
      "gram3-comparative.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1056)\n",
      "gram4-superlative.txt:\n",
      "ACCURACY TOP1: 0.00% (0/506)\n",
      "gram5-present-participle.txt:\n",
      "ACCURACY TOP1: 0.00% (0/870)\n",
      "gram6-nationality-adjective.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1160)\n",
      "gram7-past-tense.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1482)\n",
      "gram8-plural.txt:\n",
      "ACCURACY TOP1: 0.00% (0/756)\n",
      "gram9-plural-verbs.txt:\n",
      "ACCURACY TOP1: 0.00% (0/702)\n",
      "Questions seen/total: 52.24% (10210/19544)\n",
      "Semantic accuracy: 0.00%  (0/2704)\n",
      "Syntactic accuracy: 0.00%  (0/7506)\n",
      "Total accuracy: 0.00%  (0/10210)\n"
     ]
    }
   ],
   "source": [
    "main(f'models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-common-countries.txt:\n",
      "ACCURACY TOP1: 0.00% (0/506)\n",
      "capital-world.txt:\n",
      "ACCURACY TOP1: 0.00% (0/4524)\n",
      "currency.txt:\n",
      "ACCURACY TOP1: 0.00% (0/866)\n",
      "city-in-state.txt:\n",
      "ACCURACY TOP1: 0.00% (0/2467)\n",
      "family.txt:\n",
      "ACCURACY TOP1: 0.00% (0/506)\n",
      "gram1-adjective-to-adverb.txt:\n",
      "ACCURACY TOP1: 0.00% (0/992)\n",
      "gram2-opposite.txt:\n",
      "ACCURACY TOP1: 0.00% (0/812)\n",
      "gram3-comparative.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1332)\n",
      "gram4-superlative.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1122)\n",
      "gram5-present-participle.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1056)\n",
      "gram6-nationality-adjective.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1599)\n",
      "gram7-past-tense.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1560)\n",
      "gram8-plural.txt:\n",
      "ACCURACY TOP1: 0.00% (0/1332)\n",
      "gram9-plural-verbs.txt:\n",
      "ACCURACY TOP1: 0.00% (0/870)\n",
      "Questions seen/total: 100.00% (19544/19544)\n",
      "Semantic accuracy: 0.00%  (0/8869)\n",
      "Syntactic accuracy: 0.00%  (0/10675)\n",
      "Total accuracy: 0.00%  (0/19544)\n"
     ]
    }
   ],
   "source": [
    "main('data/glove/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, W = load_glove('data/glove/glove.6B.300d.txt')\n",
    "glove_vocab = Vocab(tokens, add_specials=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = Glove(glove_vocab, W.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.most_similar('queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.most_similar('girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.most_similar('boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.analogy('king', 'queen', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(glove[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
